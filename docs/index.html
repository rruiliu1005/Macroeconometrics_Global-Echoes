<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rui Liu">

<title>Macroeconometrics Research Report - Global Echoes: Analyzing the Interplay of Economic Indicators Across Leading Economies</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Macroeconometrics Research Report</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-question-objective-and-motivation" id="toc-the-question-objective-and-motivation" class="nav-link active" data-scroll-target="#the-question-objective-and-motivation">1. The Question Objective, and Motivation</a></li>
  <li><a href="#data-and-their-properties" id="toc-data-and-their-properties" class="nav-link" data-scroll-target="#data-and-their-properties">2. Data and their properties</a>
  <ul class="collapse">
  <li><a href="#data-plots" id="toc-data-plots" class="nav-link" data-scroll-target="#data-plots">Data Plots</a></li>
  <li><a href="#stationarity-check" id="toc-stationarity-check" class="nav-link" data-scroll-target="#stationarity-check">Stationarity Check</a></li>
  </ul></li>
  <li><a href="#the-model-and-hypothesis" id="toc-the-model-and-hypothesis" class="nav-link" data-scroll-target="#the-model-and-hypothesis">3. The Model and Hypothesis</a>
  <ul class="collapse">
  <li><a href="#model-1-standard-bvarp-model" id="toc-model-1-standard-bvarp-model" class="nav-link" data-scroll-target="#model-1-standard-bvarp-model">3.1 Model 1: Standard BVAR(p) Model</a>
  <ul class="collapse">
  <li><a href="#model-specification" id="toc-model-specification" class="nav-link" data-scroll-target="#model-specification">3.1.1 Model Specification</a></li>
  <li><a href="#prior-settings" id="toc-prior-settings" class="nav-link" data-scroll-target="#prior-settings">3.1.2 Prior Settings</a></li>
  <li><a href="#posterior-distributions" id="toc-posterior-distributions" class="nav-link" data-scroll-target="#posterior-distributions">3.1.3 Posterior Distributions</a></li>
  <li><a href="#estimation-procedure" id="toc-estimation-procedure" class="nav-link" data-scroll-target="#estimation-procedure">3.1.4 Estimation Procedure</a></li>
  </ul></li>
  <li><a href="#model-2-large-bvars-model-with-ma1-gaussian-innovations" id="toc-model-2-large-bvars-model-with-ma1-gaussian-innovations" class="nav-link" data-scroll-target="#model-2-large-bvars-model-with-ma1-gaussian-innovations">3.2 Model 2: Large BVARs model with MA(1) Gaussian innovations</a>
  <ul class="collapse">
  <li><a href="#model-specification-1" id="toc-model-specification-1" class="nav-link" data-scroll-target="#model-specification-1">3.2.1 Model Specification</a></li>
  <li><a href="#prior-specification" id="toc-prior-specification" class="nav-link" data-scroll-target="#prior-specification">3.2.2 Prior Specification</a></li>
  <li><a href="#posterior-distribution" id="toc-posterior-distribution" class="nav-link" data-scroll-target="#posterior-distribution">3.2.3 Posterior Distribution</a></li>
  <li><a href="#estimation-procedure-1" id="toc-estimation-procedure-1" class="nav-link" data-scroll-target="#estimation-procedure-1">3.2.4 Estimation Procedure</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#model-estimation" id="toc-model-estimation" class="nav-link" data-scroll-target="#model-estimation">4. Model Estimation</a>
  <ul class="collapse">
  <li><a href="#standard-bayesian-var" id="toc-standard-bayesian-var" class="nav-link" data-scroll-target="#standard-bayesian-var">4.1 Standard Bayesian VAR</a>
  <ul class="collapse">
  <li><a href="#model-building-code-and-validation" id="toc-model-building-code-and-validation" class="nav-link" data-scroll-target="#model-building-code-and-validation">4.1.1 Model Building Code and Validation</a></li>
  </ul></li>
  <li><a href="#large-bvars-model-with-ma1-gaussian-innovations" id="toc-large-bvars-model-with-ma1-gaussian-innovations" class="nav-link" data-scroll-target="#large-bvars-model-with-ma1-gaussian-innovations">4.2 Large BVARs model with MA(1) Gaussian innovations</a>
  <ul class="collapse">
  <li><a href="#model-building-code-and-validation-1" id="toc-model-building-code-and-validation-1" class="nav-link" data-scroll-target="#model-building-code-and-validation-1">4.2.1 Model Building Code and Validation</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Global Echoes: Analyzing the Interplay of Economic Indicators Across Leading Economies</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rui Liu </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="the-question-objective-and-motivation" class="level1">
<h1>1. The Question Objective, and Motivation</h1>
<p><strong>Objective:</strong> Construct a Bayesian Vector Autoregression model to forecast major macroeconomic indicators for the United States, Australia, Japan, and China to facilitate an investigation into the prospective interdependencies between the economies of these nations.</p>
<p><strong>Question:</strong> This research project will examine how trade relationships, investment flows, monetary policy environments, and economic performances within the United States, Australia, Japan and China mutually influence each other, and assess the implications of these interactions for predicting future values of these economic indicators.</p>
<p><strong>Motivation:</strong> Since the onset of the COVID-19 pandemic, the global economic landscape has witnessed a series of unprecedented shifts in key macroeconomic indicators, spurred by governments‚Äô adoption of varied expansionary monetary policies. Initially, to buffer their economies, many nations implemented expansive monetary strategies, later swiftly transitioning to interest rate hikes in a bid to manage surging inflation rates‚Äîa scenario not seen in decades. The pandemic‚Äôs disruption to trade further exacerbated inflationary pressures for some economies, highlighting the intricate interdependencies among major economies with significant trade and financial ties. This period recorded stark contrast in inflation levels, with unprecedented highs in the US and Australia and notably low inflation in China and Japan. Amidst this turmoil, a divergence in economic paths also became apparent, the United States and Australia have witness robust economic rebounds, whereas China and Japan saw more tepid recoveries. This research aims to dissect the nuanced web of economic interdependencies between the United States, Australia, Japan, and China, analyzing how their trade relationships, investment flows, and monetary policy environments have mutually influenced their economic performances. Additionally, it seeks to understand the ramifications of these dynamics for the predictive accuracy of future economic indicators, offering insights into the evolving global economic order.</p>
</section>
<section id="data-and-their-properties" class="level1">
<h1>2. Data and their properties</h1>
<p><strong>Proposed Dataset:</strong> This research project will utilize data from the International Monetary Fund‚Äôs (IMF) extensive database, which offers a comprehensive collection of global economic information. The IMF‚Äôs collection includes several key databases such as the World Economic Outlook Databases, International Financial Statistics (IFS), Government Finance Statistics. The analysis will predominantly focus on the IFS database, which encompasses an sizeable collection of financial and economic data from across the global, featuring 1,681 distinct indicators such as consumer price index, interest rates, exchange rates, national accounts, government finance statistics. The data is available in various frequencies ‚Äì annual, semi-annual, quarterly, monthly, daily, and weekly. As this research is primarily focused on analyzing macroeconomic data that are published on a monthly or quarterly basis, quarterly data from Q1 2011 to Q3 2023 will be used. The analysis will examine key macroeconomic variables including consumer price indexes, foreign direct investments, exchange rates, balance of payments, and the national gross domestic product of the United States, Australia, Japan, and China.</p>
<p><strong>Variables and Motivation:</strong></p>
<table class="table">
<colgroup>
<col style="width: 47%">
<col style="width: 20%">
<col style="width: 10%">
<col style="width: 8%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Variables</th>
<th>Original Unit</th>
<th>Final Unit</th>
<th>Mnemonic</th>
<th>Code</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prices, Consumer Price Index, All items, Previous period</td>
<td>% Change</td>
<td>% Change</td>
<td>CPI</td>
<td>PCPI_PC_PP_PT</td>
</tr>
<tr class="even">
<td>International Investment Positions, assets, Direct Investment</td>
<td>US dollar, millions</td>
<td>% Change</td>
<td>FDI</td>
<td>IAD_BP6_USD</td>
</tr>
<tr class="odd">
<td>Exchange Rates, Domestic Currency per U.S. Dollar, Period Average</td>
<td>US dollar, millions</td>
<td>% Change</td>
<td>XCH</td>
<td>ENDA_XDC_USD_R</td>
</tr>
<tr class="even">
<td>Balance of Payments, Current Account, Goods and Services, Net</td>
<td>US dollar, millions</td>
<td>% Change</td>
<td>BOP</td>
<td>BGS_BP6_USD</td>
</tr>
<tr class="odd">
<td>Gross Domestic Product, Nominal, Unadjusted, Domestic Currency</td>
<td>Domestic Currency</td>
<td>% Change</td>
<td>GDP</td>
<td>NGDP_NSA_XDC</td>
</tr>
</tbody>
</table>
<p>The variables included in this study were chosen with the objective to include key economic indicators that are susceptible to changes in other nations while also having experienced significant fluctuations over the past decade. These variables were chosen not only for their ability to provide insights into the trade relations, investment dynamics and monetary policy frameworks, but also for their roles as barometers of overall economic health and performance. Foreign direct investment (FDI) is a direct indicator of cross- border investment flows and serves as a proxy for economic confidence and integration between nations. Exchange rates directly impact trade balances and investment flows, influencing economic performances. By examining the volatility and trends in exchange rates, insights can be gleaned into how monetary policies and economic conditions in one country can affect its trade partners. Balance of payments is a comprehensive measure that captures the transactions between a country and the rest of the world, offering a holistic view of its economic interactions. For example, some view changes in balance of payments as largely a result of imports and exports, which can cause one country to import the inflation of another country and vice versa. GDP growth is the ultimate measure of economic performance, encapsulating the outcome of various economic activities and policies. Analyzing GDP in the form of percentage change allows for assessing economic momentum and comparing growth rates across countries and over time, offering a clear picture of economic health and trends. Foreign direct investment, exchange rates, balance of payments and gross domestic products were transformed into percentage change from the previous period, aiming to standardize the data, facilitate temporal comparisons and enhancing the interpretability of trends over time. The presence of cyclical trends in the variables, alongside the observed impact of lagged values on future outcomes, highlights the suitability of the Bayesian Vector Autoregression model for our analysis. This model can well capture the temporal dynamics and interdependencies inherent in these economic indicators, offering a robust framework for understanding the nuanced interactions and feedback loops that characterize their behavior over time.</p>
<section id="data-plots" class="level2">
<h2 class="anchored" data-anchor-id="data-plots">Data Plots</h2>
<p><strong>Original Variables</strong></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="1152"></p>
</figure>
</div>
</div>
</div>
<p><strong>Transformed Variables</strong></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="1152"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="stationarity-check" class="level2">
<h2 class="anchored" data-anchor-id="stationarity-check">Stationarity Check</h2>
<p><strong>Stationary Tests</strong></p>
<p>The Augmented Dickey-Fuller Test is used in this section to test the null hypothesis that a unit root is present in the time series and the time series is non-stationary.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<caption>ADF Test Results for CPI Data by Country</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Dickey-Fuller Statistic</th>
<th style="text-align: left;">Lag Order</th>
<th style="text-align: left;">P-value</th>
<th style="text-align: left;">Country</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">-3.537365</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.04688628</td>
<td style="text-align: left;">China</td>
</tr>
<tr class="even">
<td style="text-align: left;">-2.099504</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.5343704</td>
<td style="text-align: left;">Japan</td>
</tr>
<tr class="odd">
<td style="text-align: left;">-2.466873</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.3866844</td>
<td style="text-align: left;">United_States</td>
</tr>
<tr class="even">
<td style="text-align: left;">-1.548745</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.7557808</td>
<td style="text-align: left;">Australia</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The lag order chosen in the ADF test is 4, which is appropriate given our data is of quarterly frequency. The result of the ADF test on the CPI data shows that we do not have enough evidence to reject the null hypothesis that the CPI series is unit root non-stationary at 1% significance level.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<caption>ADF Test Results for Foreign Direct Investment (% change) Data by Country</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Dickey-Fuller Statistic</th>
<th style="text-align: left;">Lag Order</th>
<th style="text-align: left;">P-value</th>
<th style="text-align: left;">Country</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">-4.381655</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.01</td>
<td style="text-align: left;">China</td>
</tr>
<tr class="even">
<td style="text-align: left;">-3.753413</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.02935319</td>
<td style="text-align: left;">Japan</td>
</tr>
<tr class="odd">
<td style="text-align: left;">-3.629899</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.03957787</td>
<td style="text-align: left;">United_States</td>
</tr>
<tr class="even">
<td style="text-align: left;">-3.251905</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.08919385</td>
<td style="text-align: left;">Australia</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The ADF results shows that we have enough evidence to reject the null hypothesis that the foreign direct investment (% change) data is not unit-root stationary for Australia, the United States and Japan at 1% significance level and we do have enough evidence to reject the null hypothesis for China at 1% significance level.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<caption>ADF Test Results for Exchange Rate (% change) Data by Country</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Dickey-Fuller Statistic</th>
<th style="text-align: left;">Lag Order</th>
<th style="text-align: left;">P-value</th>
<th style="text-align: left;">Country</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">-3.062323</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.1481656</td>
<td style="text-align: left;">China</td>
</tr>
<tr class="even">
<td style="text-align: left;">-3.278626</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.08503945</td>
<td style="text-align: left;">Japan</td>
</tr>
<tr class="odd">
<td style="text-align: left;">-2.92166</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.2045889</td>
<td style="text-align: left;">Australia</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The result of the ADF test on the exchange rate data shows that we do not have enough evidence to reject the null hypothesis that the exchange rate (%change) against the dollar series is unit root non-stationary at 1% significance level.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<caption>ADF Test Results for Balance of Payments (% change) Data by Country</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Dickey-Fuller Statistic</th>
<th style="text-align: left;">Lag Order</th>
<th style="text-align: left;">P-value</th>
<th style="text-align: left;">Country</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">-5.055137</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.01</td>
<td style="text-align: left;">China</td>
</tr>
<tr class="even">
<td style="text-align: left;">-2.491177</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.3772656</td>
<td style="text-align: left;">Japan</td>
</tr>
<tr class="odd">
<td style="text-align: left;">-2.256564</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.4713741</td>
<td style="text-align: left;">United_States</td>
</tr>
<tr class="even">
<td style="text-align: left;">-3.495297</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.05135306</td>
<td style="text-align: left;">Australia</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The result of the ADF test on the balance of payments data shows that we do not have enough evidence to reject the null hypothesis that the balance of payments (%change) series is unit root non-stationary at 5% significance level for all countries except for China.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<caption>ADF Test Results for GDP (% change) Data by Country</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Dickey-Fuller Statistic</th>
<th style="text-align: left;">Lag Order</th>
<th style="text-align: left;">P-value</th>
<th style="text-align: left;">Country</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">-2.699632</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.2936494</td>
<td style="text-align: left;">China</td>
</tr>
<tr class="even">
<td style="text-align: left;">-2.528094</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.3624574</td>
<td style="text-align: left;">Japan</td>
</tr>
<tr class="odd">
<td style="text-align: left;">-2.894114</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.2156383</td>
<td style="text-align: left;">United_States</td>
</tr>
<tr class="even">
<td style="text-align: left;">-3.114811</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">0.1271114</td>
<td style="text-align: left;">Australia</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The result of the ADF test on the GDP data shows that we do not have enough evidence to reject the null hypothesis that the GDP (%change) series is unit root non-stationary at 5% significance level.</p>
<p>The results from the ADF tests indicates that further transformations are needed to achieve stationarity for most of the variables included in this research.</p>
</section>
</section>
<section id="the-model-and-hypothesis" class="level1">
<h1>3. The Model and Hypothesis</h1>
<p>We will employ four models to address our proposed problem. Firstly, we will use a standard Bayesian Vector Autoregressive (BVAR) model with independently and indentically distributed innovations, as outlined in details in <span class="citation" data-cites="wozniakBsvarsBayesianEstimation2022">Wo≈∫niak (<a href="#ref-wozniakBsvarsBayesianEstimation2022" role="doc-biblioref">2022</a>)</span>. Additionally, we will investigate a large BVAR model with flexible error covariance structures, following the methodology proposed by <span class="citation" data-cites="Chan_2015">Chan (<a href="#ref-Chan_2015" role="doc-biblioref">2015</a>)</span>. Specifically, the second model will incorporate MA(1) Gaussian innovations to better account for potential model misspecifications such as omitted variable bias and to facilitate shrinkage in VAR coefficients. Our third model will be a BVAR incorporating t-distributed innovations to better handle outliers than the Gaussian approach, which will be useful to handle extreme events like the Covid-19 Global Pandemic and economic slow down. The final model will combined a common stochastic volatility frame work with t-distributed innovations, offering a robust approach to volatility modelling.</p>
<section id="model-1-standard-bvarp-model" class="level2">
<h2 class="anchored" data-anchor-id="model-1-standard-bvarp-model">3.1 Model 1: Standard BVAR(p) Model</h2>
<section id="model-specification" class="level3">
<h3 class="anchored" data-anchor-id="model-specification">3.1.1 Model Specification</h3>
<p><span class="math display">\[ Y = XA+E\]</span> <span class="math display">\[E|X \sim \mathcal{MN}_{T \times N}(0_{T \times N},\Sigma_{N \times N}, I_T)\]</span> <span class="math display">\[
A = \begin{bmatrix}
\mu_0^T \\
A_1^T \\
\vdots \\
A_p^T
\end{bmatrix}
, \quad
Y = \begin{bmatrix}
y_1^T \\
y_2^T \\
\vdots \\
y_T^T
\end{bmatrix}
, \quad
x_t = \begin{bmatrix}
1 \\
y_{t-1}^T \\
\vdots \\
y_{t-p}^T
\end{bmatrix}
, \quad
X = \begin{bmatrix}
x_1^T \\
x_2^T \\
\vdots \\
x_T^T
\end{bmatrix}
, \quad
E = \begin{bmatrix}
e_1^T \\
e_2^T \\
\vdots \\
e_T^T
\end{bmatrix}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(T\)</span> is the number of time periods under consideration</li>
<li><span class="math inline">\(N\)</span> is the number of variables, in our case, N = 20</li>
<li><span class="math inline">\(P\)</span> is the number of lags</li>
<li><span class="math inline">\(Y\)</span> is a <span class="math inline">\(T \times N\)</span> matrix of variables of response variables we aim to model.</li>
<li><span class="math inline">\(A\)</span> is a <span class="math inline">\(K \times N\)</span> matrix of coefficients, <span class="math inline">\(K = (1+ùëù\times N)\)</span>.</li>
<li><span class="math inline">\(E\)</span> is a <span class="math inline">\(T \times N\)</span> matrix of the error terms</li>
<li><span class="math inline">\(X\)</span> is a <span class="math inline">\(T \times (1+ùëù\times N)\)</span> matrix of covariates</li>
<li><span class="math inline">\(\Sigma\)</span> is a <span class="math inline">\(N \times N\)</span> matrix representing the row-specific covariance matrix</li>
<li><span class="math inline">\(I_T\)</span> is a <span class="math inline">\(T \times T\)</span> identity matrix representing the column specific covariance matrix</li>
<li><span class="math inline">\(E|X\)</span> follows a matrix-variate normal distribution with mean <span class="math inline">\(0_{T \times N}\)</span>, row specific covariance matrix <span class="math inline">\(\Sigma_{N \times N}\)</span> and column specific covariance matrix <span class="math inline">\(I_T\)</span></li>
</ul>
<p>The Bayesian Vector Autoregression model as formulated above provides a robust framework for investigating the relationships among selected economic indicators across different nations. By employing this model, this research aims to quantitatively measure the influence of one country‚Äôs economic indicators on another, such as how lagged changes in China‚Äôs inflation rate, may influence the GDP growth rate of the United States and vice versa. The BVAR model, with its estimation of coefficients across various lags, offers a deep understanding of both immediate and more delayed economic interactions, which is crucial to analyzing the cyclical nature of trade relationships, investment flows, monetary policy environments, and economic performances and the transmission of these metrics across borders.</p>
<p>The strength of this BVAR model lies in its ability to incorporate prior economic knowledge and beliefs into the estimation process. By setting prior distributions for the matrix of coefficients A and the covariance matrix <span class="math inline">\(\Sigma\)</span>, the model can be tailors to reflect established economic theories regarding international economic linkages and the time it takes for policy changes in one country to affect another. By calibrating the prior variances, particularly for the autoregressive coefficients, we can integrate prior knowledge or hypotheses, such as the presence of unit roots or the diminishing influence of distant lags on current values, into the analysis. When interpreting the estimation output, attention will be given to the posterior means and variances of the coefficients, which represent the model‚Äôs ‚Äúlearnt‚Äù understanding of the underlying economic structure. The analysis will be supplemented by forecast error variance decompositions to better understand the proportion of the movements in economic indicators that can be accounted for by their own shocks versus shocks to other variables.</p>
<p>The economic context underscoring this analysis is the increased globalization over the past decade, marking an era where economies are more intertwined than ever through trade, capital flows, and policy decisions. This period has witnessed not only the strengthening of global economic ties but also recent calls from political leaders advocating for a reduction in globalization. These contrasting dynamics highlight the complexity of the current global economic landscape, where the push for deeper integration coexists with growing sentiments for retrenchment. This dual trend sets the stage for our investigation, providing a rich context to explore how economic variables across nations influence each other amidst fluctuating levels of global interconnectedness. In this environment, understanding the cross-country spillover effects is vital for policymakers and businesses alike, as decisions made in one country can have far-reaching implications. By addressing these aspects, this research will contribute to the discourse on economic policy formulation, risk assessment, and strategic planning.</p>
</section>
<section id="prior-settings" class="level3">
<h3 class="anchored" data-anchor-id="prior-settings">3.1.2 Prior Settings</h3>
<p>We will employ a Normal-Inverse Wshart distribution for the joint distribution of coefficient matrices A and the row-specific variance matrix <span class="math inline">\(\Sigma\)</span>. Specifically, we have:</p>
<p><span class="math display">\[\Sigma \sim \mathcal{IW}(S_0, \nu_0) \]</span></p>
<p><span class="math display">\[p(\Sigma) \propto |\Sigma|^{-\frac{\nu_0+N+1}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}S_0))\]</span></p>
<p><span class="math display">\[A|\Sigma \sim \mathcal{MN}_{K \times N}(A_0, \Sigma, V_A)\]</span></p>
<p><span class="math display">\[p(A|\Sigma) \propto |\Sigma|^{-\frac{K}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}(A-A_0)^T(A-A_0)))\]</span></p>
<p><span class="math display">\[(A,\Sigma) \sim \mathcal{NIW}_{K \times N} (A_0, V_A, S_0, \nu_0)\]</span></p>
<p><span class="math display">\[p(A,\Sigma) \propto |\Sigma|^{-\frac{K+\nu_0+N+1}{2}} \times exp(-\frac{1}{2}tr(\Sigma^{-1}S_0))\times exp(-\frac{1}{2}tr(\Sigma^{-1}(A-A_0)^T(A-A_0)))\]</span></p>
<p>where</p>
<p><span class="math display">\[V_A = diag(v_{A,ii})\]</span></p>
<p><span class="math display">\[v_{A,ii} = \begin{cases}
\kappa_l(\frac{l^2}{\hat{s}_r}) &amp; \text{for a coefficient associated to lag l of variable r} \\
\kappa_2&amp; \text{for an intercept}
\end{cases}\]</span></p>
<p>where <span class="math inline">\(\hat{s}_r\)</span> is the sample variance of an AR(4) model for the variable r.</p>
<p>Additionally, we adopt commonly used values for the hyperparameters as established in the literature.</p>
<p><span class="math display">\[A_0 = 0\]</span></p>
<p><span class="math display">\[v_0 = N+3\]</span></p>
<p><span class="math display">\[S_0 = I_N\]</span></p>
<p><span class="math display">\[\kappa_1 = 0.2^2 \quad \kappa_2 = 10^2\]</span></p>
<p>The hyperparameters <span class="math inline">\(\kappa_1\)</span> and <span class="math inline">\(\kappa_2\)</span> are specified in a way such that the coefficient associated with a lag l variable is shrunk more heavily to - as lag length increases whereas the intercepts are not shrunk to 0.</p>
</section>
<section id="posterior-distributions" class="level3">
<h3 class="anchored" data-anchor-id="posterior-distributions">3.1.3 Posterior Distributions</h3>
<p>The posterior distribution specified above has the form</p>
<p><span class="math display">\[p(Y|A, \Sigma) = (2\pi)^{-\frac{Tn}{2}}|\Sigma|^{-\frac{T}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}(Y-XA)^T(Y-XA))\]</span></p>
<p>and the joint posterior distribution</p>
<p><span class="math display">\[p(A, \Sigma \mid Y)  = \frac{p(A,\Sigma,Y)}{p(Y)}\propto p(A, \Sigma, Y) \propto p(Y|A,\Sigma)\times p(A,\Sigma) =  p(Y|A,\Sigma) p(A \mid \Sigma) p(\Sigma)\]</span></p>
<p><span class="math display">\[\propto |\Sigma|^{-\frac{T}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}(Y-XA)^T(Y-XA))) \times\]</span></p>
<p><span class="math display">\[\mid \Sigma \mid^{-\frac{\nu_0+N+K}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}S_o))exp(-\frac{1}{2}tr(\Sigma^{-1}(A-A_0)^TV_A^{-1}(A-A_0))\]</span></p>
<p><span class="math display">\[\propto |\Sigma|^{-\frac{T+N+K+\nu_0+1}{2}} \times \exp (-\frac{1}{2}tr(\Sigma^{-1}S_0)) \times \]</span></p>
<p><span class="math display">\[exp(-\frac{1}{2}tr(\Sigma^{-1}(A_0^TV_a^{-1}A_0+Y^TY-\bar{A}^T\bar{V}^{-1}\bar{A})\times\]</span> <span class="math display">\[exp(-\frac{1}{2}tr(\Sigma^{-1}(A-\bar{A})^T\bar{V}^{-1}(A-\bar{A})))\]</span> Hence,</p>
<p><span class="math display">\[p(A, \Sigma \mid Y, X) = p(A \mid Y, X, \Sigma) p(\Sigma \mid Y, X)\]</span></p>
<p><span class="math display">\[p(A \mid Y, X, \Sigma) = \mathcal{MN}_{k \times N}(\bar{A}, \Sigma, \bar{V})\]</span></p>
<p><span class="math display">\[p(\Sigma \mid Y, X) = \mathcal{IW}_N(\bar{S}, \bar{\nu})\]</span></p>
<p>where</p>
<p><span class="math display">\[\bar{V} = (X^TX + V_A^{-1})^{-1}\]</span></p>
<p><span class="math display">\[\bar{A} = \bar{V}(X^TY + V_A^{-1}A_0)\]</span></p>
<p><span class="math display">\[\bar{\nu} = T + \nu_0\]</span></p>
<p><span class="math display">\[\bar{S} = S_0 + Y^TY + A_0^TV_A^{-1}A_0 - \bar{A}^T\bar{V}^{-1}\bar{A}\]</span></p>
</section>
<section id="estimation-procedure" class="level3">
<h3 class="anchored" data-anchor-id="estimation-procedure">3.1.4 Estimation Procedure</h3>
<p>In this setting, we have</p>
<ul>
<li><span class="math inline">\((A,\Sigma) \sim \mathcal{NIW}_{K \times N} (A_0, V_A, S_0, \nu_0)\)</span></li>
</ul>
<p>then, prior draws can be sampled from</p>
<ul>
<li><span class="math inline">\(\Sigma \sim \mathcal{IW}(S_0, \nu_0)\)</span></li>
<li><span class="math inline">\(A|\Sigma \sim \mathcal{MN}_{K \times N}(A_0, \Sigma, V_A)\)</span></li>
</ul>
<p>we use the following Gibb‚Äôs Sampler algorithm to sample from the posterior distribution:</p>
<ul>
<li>Initialize <span class="math inline">\(\Sigma\)</span> at <span class="math inline">\(\Sigma^0\)</span></li>
<li>For <span class="math inline">\(s = 1,...,S_1+S_2\)</span>
<ol type="1">
<li>Draw a sample <span class="math inline">\(A^{(s)}\)</span> from <span class="math inline">\(p(A \mid Y, X, \Sigma^{(s-1)}) \sim \mathcal{MN}_{k \times N}(\bar{A}, \Sigma, \bar{V})\)</span></li>
<li>Draw a sample <span class="math inline">\(\Sigma^{(s)}\)</span> from <span class="math inline">\(p(\Sigma \mid Y, X, A^{(s)}) = \mathcal{IW}_N(\bar{S}, \bar{\nu})\)</span></li>
</ol></li>
</ul>
<p>We discard the first <span class="math inline">\(S_1\)</span> sample draws to allow the algorithm to converge to the stationary posterior distributiion to obtain <span class="math inline">\(S_2\)</span> sampled draws from the joint posterior distribution.</p>
<p><span class="math display">\[\left\{A^{(s)}, \Sigma^{(s)}\right\}_{s=S_1+1}^{S_1+S_2}\]</span></p>
<p>The draws from joint predictive density can then be obtained using the following algorithm:</p>
<ol type="1">
<li>Sample S draws <span class="math inline">\(\left\{ A^{(s)}, \Sigma^{(s)} \right\}_{s=1}^{S}\)</span> from <span class="math inline">\(p(A,\Sigma|Y, X)\)</span></li>
<li>Sample S draws <span class="math inline">\(\left\{ Y_{t+h}^{(s)} \right\}_{s=1}^S\)</span> from <span class="math inline">\(Y_{t+h}^{(s)} \sim \mathcal{N}_{hN}(Y_{t+h|t}(A^{(s)}), \mathbb{V}ar[Y_{t+h|t}]|A^{(s)}, \Sigma^{(s)}]\)</span></li>
</ol>
</section>
</section>
<section id="model-2-large-bvars-model-with-ma1-gaussian-innovations" class="level2">
<h2 class="anchored" data-anchor-id="model-2-large-bvars-model-with-ma1-gaussian-innovations">3.2 Model 2: Large BVARs model with MA(1) Gaussian innovations</h2>
<section id="model-specification-1" class="level3">
<h3 class="anchored" data-anchor-id="model-specification-1">3.2.1 Model Specification</h3>
<p>Incorporating MA(1) Gaussian innovations in a large BVARs model lead to a significant enhancement over traditional BVAR models, especially when forecasting macroeconomic variables for several reasons. Firstly, the variances of economic shocks is rarely constant over time. For example, volatility tends to cluster during periods of economic crisis and is more tranquil during stable times. Incorporating stochastic volatility allows the model to adapt to changing volatility in the data, improving forecasting performance especially in the presence of financial market instability or economic policy shifts. In addition, by allowing for serial correlation in the innovations term, we will be able to capture the momentum or persistence in economic variables that is often observed in real-world data. Recognizing that shocks may have a lasting impact over several periods can enhance the model‚Äôs ability to predict future values by considering the path-dependent nature of the economy. Our BVAR model with common stochastic volatility is a natural extension to the standard BVAR model and formulated as below:</p>
<p><span class="math display">\[ Y = XA+E\]</span></p>
<p>where</p>
<p><span class="math display">\[
A = \begin{bmatrix}
\mu_0^T \\
A_1^T \\
\vdots \\
A_p^T
\end{bmatrix}
, \quad
Y = \begin{bmatrix}
y_1^T \\
y_2^T \\
\vdots \\
y_T^T
\end{bmatrix}
, \quad
x_t = \begin{bmatrix}
1 \\
y_{t-1}^T \\
\vdots \\
y_{t-p}^T
\end{bmatrix}
, \quad
X = \begin{bmatrix}
x_1^T \\
x_2^T \\
\vdots \\
x_T^T
\end{bmatrix}
, \quad
E = \begin{bmatrix}
e_1^T \\
e_2^T \\
\vdots \\
e_T^T
\end{bmatrix}
\]</span> where</p>
<ul>
<li><span class="math inline">\(T\)</span> is the number of time periods under consideration</li>
<li><span class="math inline">\(N\)</span> is the number of variables, in our case, N = 20</li>
<li><span class="math inline">\(P\)</span> is the number of lags</li>
<li><span class="math inline">\(Y\)</span> is a <span class="math inline">\(T \times N\)</span> matrix of variables of response variables we aim to model.</li>
<li><span class="math inline">\(A\)</span> is a <span class="math inline">\(K \times N\)</span> matrix of coefficients, <span class="math inline">\(K = (1+ùëù\times N)\)</span></li>
<li><span class="math inline">\(E\)</span> is a <span class="math inline">\(T \times N\)</span> matrix of the error terms</li>
<li><span class="math inline">\(X\)</span> is a <span class="math inline">\(T \times (1+ùëù\times N)\)</span> matrix of covariates</li>
<li><span class="math inline">\(\Sigma\)</span> is a <span class="math inline">\(N \times N\)</span> matrix representing the row-specific covariance matrix</li>
</ul>
<p>the same as before. But, instead of the column specific matrix as the identity matrix, we specify the column specific matrix as a diagonal matrix <span class="math inline">\(\Omega\)</span>. Specifically, we have:</p>
<p><span class="math display">\[E|X \sim \mathcal{MN}_{T \times N}(0_{T \times N},\Sigma_{N \times N}, \Omega_{T \times T})\]</span></p>
<p>and,</p>
<p><span class="math display">\[\epsilon_t = u_t + \psi_1 u_{t-1}\]</span></p>
<p><span class="math display">\[u_t \sim \mathcal{N}(0,e^{h_t} \Sigma)\]</span></p>
<p><span class="math display">\[h_t = \rho h_{t-1} + u_t^h \quad \text{ follows an Autoregressive process of lag 1 AR(1), and}\]</span></p>
<p><span class="math display">\[u_t^h \sim N(0,\sigma_h^2)\]</span></p>
<p><span class="math display">\[\Omega = \left(
\begin{array}{cccc}
(1 + \psi_1^2) e^{h_1} &amp; \psi_1 e^{h_1} &amp; \cdots &amp; 0 \\
\psi_1 e^{h_1} &amp; \psi_1^2 e^{h_1} + e^{h_2} &amp; \cdots &amp; \vdots \\
0 &amp; \cdots &amp; \ddots &amp; \vdots \\
\vdots &amp; \cdots &amp; \psi_1^2 e^{h_{T-2}} + e^{h_{T-1}} &amp; \psi_1 e^{h_{T-1}} \\
0 &amp; \cdots &amp; \psi_1 e^{h_{T-1}} &amp; \psi_1^2 e^{h_{T-1}} + e^{h_T}
\end{array}
\right)\]</span></p>
<p>In this specification, each element of <span class="math inline">\(e_t\)</span> may have distinct variances, and the variances of all innovations can be scaled by a common factor. This approach is economically intuitive, as the volatility of macroeconomic variables often exhibit co-movement. It is important to emphasize that each component of <span class="math inline">\(e_t\)</span> must adhere to the same univariate time series model.</p>
</section>
<section id="prior-specification" class="level3">
<h3 class="anchored" data-anchor-id="prior-specification">3.2.2 Prior Specification</h3>
<p>Here, we consider a priori independent distributions for <span class="math inline">\((A, \Sigma, \Omega)\)</span>, namely:</p>
<p><span class="math display">\[p(A, \Sigma, \Omega) = p(A, \Sigma) \times p(\Omega)\]</span> Given this structure, we can sample from the posterior distribution by sequentially sampling from:</p>
<ul>
<li><span class="math inline">\(P(A, \Sigma | Y, X, \Omega)\)</span></li>
<li><span class="math inline">\(P(\Omega | Y, X, A, \Sigma)\)</span></li>
</ul>
<p>The prior distribution of <span class="math inline">\((A,\Sigma)\)</span> follow the same normal inverse Wishart prior distribution as outlined in model one.</p>
<p>For the moving average coefficients, we adopt an uninformative truncated normal prior for the MA coefficient <span class="math inline">\(\psi\)</span>:</p>
<p><span class="math display">\[
\psi \sim \mathcal{N}(\psi_0, V_\psi) \mathbb{1}(|\psi|&lt;1)
\]</span></p>
<p>and we set <span class="math inline">\(\psi_0 = 0\)</span> and <span class="math inline">\(V_\psi = 1\)</span> so that the prior centers around 0 with a relatively large variance and has support within (-1,1). Further more, we assume independent priors for <span class="math inline">\(\sigma^2_h\)</span> and <span class="math inline">\(\rho\)</span>:</p>
<p><span class="math display">\[\sigma_h^2 \sim \mathcal{IG}(\nu_{h_0}, s_{h_0})\]</span></p>
<p><span class="math display">\[\rho \sim \mathcal{N}(\rho_0, V_\rho) \mathbb{1}(|\rho|&lt;1)\]</span></p>
<p>We set the hyperparameters <span class="math inline">\(\nu_{h_0} = 5\)</span>, <span class="math inline">\(s_{h_0} = 0.04\)</span>, <span class="math inline">\(\rho_0 = 0.9\)</span> and <span class="math inline">\(V_\rho = 0.04\)</span> so that the prior mean of <span class="math inline">\(\sigma_h^2\)</span> is 0.01 and <span class="math inline">\(\rho\)</span> is centered at 0.9.</p>
</section>
<section id="posterior-distribution" class="level3">
<h3 class="anchored" data-anchor-id="posterior-distribution">3.2.3 Posterior Distribution</h3>
<p>The posterior distribution specified above has the form</p>
<p><span class="math display">\[p(Y|A, \Sigma) = (2\pi)^{-\frac{Tn}{2}}|\Sigma|^{-\frac{T}{2}}|\Omega|^{-\frac{N}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}(Y-XA)^T\Omega^{-1}(Y-XA))\]</span></p>
<p>and the joint posterior distribution</p>
<p><span class="math display">\[p(A, \Sigma \mid Y, \Omega)  = \frac{p(A,\Sigma,Y, \Omega)}{p(Y, \Omega)}\]</span> <span class="math display">\[\propto p(A, \Sigma, Y, \Omega) \propto p(Y \mid A,\Sigma, \Omega)\times p(A,\Sigma, \Omega)\]</span> <span class="math display">\[=  p(Y \mid A,\Sigma, \Omega) p(A, \Sigma) p(\Omega) = p(Y \mid A,\Sigma, \Omega) p(A \mid \Sigma) p(\Sigma) p(\Omega)\]</span></p>
<p><span class="math display">\[\propto p(Y \mid A,\Sigma, \Omega) p(A \mid \Sigma) p(\Sigma)\]</span></p>
<p><span class="math display">\[\propto |\Sigma|^{-\frac{T}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}(Y-XA)^T\Omega^{-1}(Y-XA)) \times\]</span></p>
<p><span class="math display">\[\mid \Sigma \mid^{-\frac{\nu_0+N+K}{2}}exp(-\frac{1}{2}tr(\Sigma^{-1}S_o))exp(-\frac{1}{2}tr(\Sigma^{-1}(A-A_0)^TV_A^{-1}(A-A_0))\]</span></p>
<p><span class="math display">\[\propto |\Sigma|^{-\frac{T+N+K+\nu_0+1}{2}} \times \exp (-\frac{1}{2}tr(\Sigma^{-1}S_0)) \times \]</span> <span class="math display">\[exp(-\frac{1}{2}tr(\Sigma^{-1}(A_0^TV_a^{-1}A_0+Y^T\Omega^{-1}Y-\bar{A}^T\bar{V}^{-1}\bar{A})\times\]</span> <span class="math display">\[exp(-\frac{1}{2}tr(\Sigma^{-1}(A-\bar{A})^T\bar{V}^{-1}(A-\bar{A})))\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[p(A, \Sigma \mid Y, X) = p(A \mid Y, X, \Sigma) p(\Sigma \mid Y, X)\]</span></p>
<p><span class="math display">\[p(A \mid Y, X, \Sigma, \Omega) = \mathcal{MN}_{k \times N}(\bar{A}, \Sigma, \bar{V})\]</span></p>
<p><span class="math display">\[p(\Sigma \mid Y, X) = \mathcal{IW}_N(\bar{S}, \bar{\nu})\]</span></p>
<p>where</p>
<p><span class="math display">\[\bar{V} = (X^T\Omega^{-1}X + V_A^{-1})^{-1}\]</span></p>
<p><span class="math display">\[\bar{A} = \bar{V}(X^T\Omega^{-1}Y + V_A^{-1}A_0)\]</span></p>
<p><span class="math display">\[\bar{\nu} = T + \nu_0\]</span></p>
<p><span class="math display">\[\bar{S} = S_0 + Y^T\Omega^{-1}Y + A_0^TV_A^{-1}A_0 - \bar{A}^T\bar{V}^{-1}\bar{A}\]</span></p>
</section>
<section id="estimation-procedure-1" class="level3">
<h3 class="anchored" data-anchor-id="estimation-procedure-1">3.2.4 Estimation Procedure</h3>
<p>In this setting, we have</p>
<ul>
<li><span class="math inline">\((A,\Sigma) \sim \mathcal{NIW}_{K \times N} (A_0, V_A, S_0, \nu_0)\)</span></li>
<li><span class="math inline">\(p(A, \Sigma, \Omega) = p(A, \Sigma) \times p(\Omega)\)</span></li>
</ul>
<p>then, prior draws can be sampled from</p>
<ul>
<li><p><span class="math inline">\(\Sigma \sim \mathcal{IW}(S_0, \nu_0)\)</span></p></li>
<li><p><span class="math inline">\(A|\Sigma \sim \mathcal{MN}_{K \times N}(A_0, \Sigma, V_A)\)</span></p></li>
<li><p><span class="math inline">\(\Omega = \left(
\begin{array}{cccc}
(1 + \psi_1^2) e^{h_1} &amp; \psi_1 e^{h_1} &amp; \cdots &amp; 0 \\
\psi_1 e^{h_1} &amp; \psi_1^2 e^{h_1} + e^{h_2} &amp; \cdots &amp; \vdots \\
0 &amp; \cdots &amp; \ddots &amp; \vdots \\
\vdots &amp; \cdots &amp; \psi_1^2 e^{h_{T-2}} + e^{h_{T-1}} &amp; \psi_1 e^{h_{T-1}} \\
0 &amp; \cdots &amp; \psi_1 e^{h_{T-1}} &amp; \psi_1^2 e^{h_{T-1}} + e^{h_T}
\end{array}
\right)\)</span></p></li>
<li><p><span class="math inline">\(\epsilon_t = u_t + \psi_1 u_{t-1}\)</span></p></li>
<li><p><span class="math inline">\(\psi \sim \mathcal{N}(\psi_0, V_\psi) \mathbb{1}(|\psi|&lt;1)\)</span></p></li>
<li><p><span class="math inline">\(u_t \sim \mathcal{N}(0,e^{h_t} \Sigma)\)</span></p></li>
<li><p><span class="math inline">\(h_t = \rho h_{t-1} + u_t^h\)</span></p></li>
<li><p><span class="math inline">\(\rho \sim \mathcal{N}(\rho_0, V_\rho) \mathbb{1}(|\rho|&lt;1)\)</span></p></li>
<li><p><span class="math inline">\(u_t^h \sim N(0,\sigma_h^2)\)</span></p></li>
<li><p><span class="math inline">\(\sigma_h^2 \sim \mathcal{IG}(\nu_{h_0}, s_{h_0})\)</span></p></li>
</ul>
<p>To sample <span class="math inline">\(S_1+S_2\)</span> draws of <span class="math inline">\(\left\{\Omega^{(s)}\right\}_{s=1}^{S_1+S_2}\)</span></p>
<ol type="1">
<li>Sample <span class="math inline">\(S_1+S_2\)</span> draws of <span class="math inline">\(\left\{\sigma^{2,(s)}_h\right\}_{s=1}^{S_1+S_2}\)</span> from <span class="math inline">\(\mathcal{IG}(v_{h_0}, s_{h_0})\)</span></li>
<li>Sample <span class="math inline">\(S_1+S_2\)</span> draws of <span class="math inline">\(\left\{\rho^{(s)}\right\}_{s=1}^{S_1+S_2}\)</span> from <span class="math inline">\(\mathcal{N}(\rho_0, V_\rho) \mathbb{1}(|\rho|&lt;1)\)</span></li>
<li>For each <span class="math inline">\(\sigma^{2,(s)}_h\)</span>, sample <span class="math inline">\(\left\{u_t^{h,(s)}\right\}_{t=1}^T\)</span> from <span class="math inline">\(N(0,\sigma_h^{2,(s)})\)</span></li>
<li>For t = 1,‚Ä¶,T and s = 1,‚Ä¶, <span class="math inline">\(S_1+S_2\)</span>, compute <span class="math inline">\(h_t^{(s)} = \rho h_{t-1}^{(s)} + u_t^{h,(s)}\)</span></li>
<li>Sample <span class="math inline">\(S_1+S_2\)</span> draws of <span class="math inline">\(\left\{u_t^{(s)}\right\}_{s=1}^{S_1+S_2}\)</span> from <span class="math inline">\(u_t \sim \mathcal{N}(0,e^{h_t^{(s)}} \Sigma)\)</span> for t = 1,‚Ä¶,T</li>
<li>Sample <span class="math inline">\(S_1+S_2\)</span> draws of <span class="math inline">\(\left\{\psi^{(s)}\right\}_{s=1}^{S_1+S_2}\)</span> from <span class="math inline">\(\mathcal{N}(\psi_0, V_\psi) \mathbb{1}(|\psi|&lt;1)\)</span></li>
<li>for each t = 1,‚Ä¶,T and s = 1,‚Ä¶<span class="math inline">\(S_1+S_2\)</span>, compute <span class="math inline">\(\epsilon_t^{(s)} = u_t^{(s)} + \psi^{(s)}u_{t-1}^{(s)}\)</span></li>
</ol>
<p>After we have obtained <span class="math inline">\(\left\{\Omega^{(s)}\right\}_{s=1}^{S_1+S_2}\)</span>, we can use the following Gibb‚Äôs Sampler algorithm to sample from the posterior distribution <span class="math inline">\(p(A \mid Y, X, \Sigma, \Omega)\)</span>:</p>
<ul>
<li>Initialize <span class="math inline">\(\Sigma\)</span> at <span class="math inline">\(\Sigma^0\)</span></li>
<li>For <span class="math inline">\(s = 1,...,S_1+S_2\)</span>
<ol type="1">
<li>Draw a sample <span class="math inline">\(A^{(s)}\)</span> from <span class="math inline">\(p(A \mid Y, X, \Omega^{(s)}, \Sigma^{(s-1)}) \sim \mathcal{MN}_{k \times N}(\bar{A}, \Sigma, \bar{V})\)</span></li>
<li>Draw a sample <span class="math inline">\(\Sigma^{(s)}\)</span> from <span class="math inline">\(p(\Sigma \mid Y, X, A^{(s)}, \Omega^{(s)}) = \mathcal{IW}_N(\bar{S}, \bar{\nu})\)</span></li>
</ol></li>
</ul>
<p>We discard the first <span class="math inline">\(S_1\)</span> sample draws to allow the algorithm to converge to the stationary posterior distributiion to obtain <span class="math inline">\(S_2\)</span> sampled draws from the joint posterior distribution.</p>
<p><span class="math display">\[\left\{A^{(s)}, \Sigma^{(s)}\right\}_{s=S_1+1}^{S_1+S_2}\]</span></p>
<p>Sampling from the joint predictive density is the same as before.</p>
</section>
</section>
</section>
<section id="model-estimation" class="level1">
<h1>4. Model Estimation</h1>
<section id="standard-bayesian-var" class="level2">
<h2 class="anchored" data-anchor-id="standard-bayesian-var">4.1 Standard Bayesian VAR</h2>
<section id="model-building-code-and-validation" class="level3">
<h3 class="anchored" data-anchor-id="model-building-code-and-validation">4.1.1 Model Building Code and Validation</h3>
<p>We verify that our model can replicate the true parameter of the data generate process by: 1. Generate artificial data containing 1000 observations simulated from a bi-variate Gaussian random walk process with the covariance matrix equal to the identity matrix of order 2. That is,</p>
<p><span class="math display">\[\mathbf{y_t} = \begin{pmatrix} y_t,1 \\ y_t,2\end{pmatrix} = \mathbf{y_{t-1}} + \mathbf{\epsilon_t} = \begin{pmatrix}y_{t-1,1}\\y_{t-1, 2}\end{pmatrix} + \begin{pmatrix}\epsilon_{t,1}\\ \epsilon_{t, 2}\end{pmatrix}\]</span> and</p>
<p><span class="math display">\[\mathbf{\epsilon} \sim iid \mathcal{N}(\mathbf{0}, \mathbf{I_2} )\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="1152"></p>
</figure>
</div>
</div>
</div>
<p>Then we estimate a model with a constant term and 1 lag using the simulated data, show that the posterior mean of the autoregressive and the covariance matrices are close to an identity matrix and that the posterior mean of the constant term is close to a vector of zeros.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior mean of autoregressive parameter:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.002 0.015
[2,] 0.999 0.000
[3,] 0.000 0.999</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior standard deviation of autoregressive parameter:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.023 0.023
[2,] 0.001 0.001
[3,] 0.001 0.001</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior mean of covariance matrix:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.101 0.000
[2,] 0.000 0.101</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior standard deviation of covariance matrix:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.005 0.003
[2,] 0.003 0.004</code></pre>
</div>
</div>
</section>
</section>
<section id="large-bvars-model-with-ma1-gaussian-innovations" class="level2">
<h2 class="anchored" data-anchor-id="large-bvars-model-with-ma1-gaussian-innovations">4.2 Large BVARs model with MA(1) Gaussian innovations</h2>
<section id="model-building-code-and-validation-1" class="level3">
<h3 class="anchored" data-anchor-id="model-building-code-and-validation-1">4.2.1 Model Building Code and Validation</h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior mean of autoregressive parameter:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.003 0.025
[2,] 0.999 0.000
[3,] 0.000 0.999</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior standard deviation of autoregressive parameter:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.031 0.031
[2,] 0.001 0.001
[3,] 0.001 0.001</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior mean of covariance matrix:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.101 0.000
[2,] 0.000 0.101</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Posterior standard deviation of covariance matrix:"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1]  [,2]
[1,] 0.004 0.003
[2,] 0.003 0.005</code></pre>
</div>
</div>
<!-- Furthermore, a non-Gaussian framework allows the modeling of asymmetries in how economies react to positive versus negative shocks. Traditional BVAR models with Gaussian assumptions is often unable to capture such nuances, while flexible error structures can incorporate the differing impacts of shocks of different magnitudes or directions. 
economic variables are often characterized by distributions that are far from Gaussian, often featuring fat tails and skewness. Secondly, -->



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Chan_2015" class="csl-entry" role="listitem">
Chan, Joshua C. 2015. <span>‚ÄúLarge Bayesian Vars: A Flexible Kronecker Error Covariance Structure.‚Äù</span> <em>SSRN Electronic Journal</em>.
</div>
<div id="ref-wozniakBsvarsBayesianEstimation2022" class="csl-entry" role="listitem">
Wo≈∫niak, Tomasz. 2022. <em>Bsvars: Bayesian Estimation of Structural Vector Autoregressive Models</em>. R Package. <a href="https://cran.r-project.org/package=bsvars">https://cran.r-project.org/package=bsvars</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>